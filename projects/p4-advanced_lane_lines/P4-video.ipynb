{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 4: Advanced Lane Finding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "In this project we would improve our technique for finding road lanes and curvature of the lanes. In order to do this, we would use a series of steps, outlined below:\n",
    "\n",
    "1. Camera Calibration\n",
    "2. Distortion Correction\n",
    "3. Color and Gradient Thresholds\n",
    "4. Perspective Transform\n",
    "5. Detect Lane Lines\n",
    "6. Determine Lane Curvature\n",
    "7. Apply these techniques to the frames of the video\n",
    "\n",
    "In this particular notebook, we would approach number 7., applying all the building blocks to the video frames!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Apply these techniques to the frames of the video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by moving over all the methods defined in the development notebook, getting them ready to use in the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "calibration_params_file = 'dist_pickle.p'\n",
    "\n",
    "with open(calibration_params_file, 'rb') as f:\n",
    "    calibration_params = pickle.load(f)\n",
    "\n",
    "mtx = calibration_params[\"mtx\"]\n",
    "dist = calibration_params[\"dist\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def undistort(img):\n",
    "    return cv2.undistort(img, mtx, dist, None, mtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_img = mpimg.imread('test_images/straight_lines1.jpg')\n",
    "test_img_size = (test_img.shape[1], test_img.shape[0])\n",
    "\n",
    "x1, y1 = (500, 480)\n",
    "x2, y2 = (780, 480)\n",
    "x3, y3 = (1200, 670)\n",
    "x4, y4 = (80, 670)\n",
    "\n",
    "src = np.float32(\n",
    "    [[x1, y1],\n",
    "     [x2, y2],\n",
    "     [x3, y3],\n",
    "     [x4, y4]])\n",
    "\n",
    "offset = 10\n",
    "dst = np.float32(\n",
    "    [[offset, offset],\n",
    "     [test_img_size[0] - offset, offset],\n",
    "     [test_img_size[0] - offset, test_img_size[1] - offset],\n",
    "     [offset, test_img_size[1] - offset]])\n",
    "\n",
    "M = cv2.getPerspectiveTransform(src, dst)\n",
    "M_inv = cv2.getPerspectiveTransform(dst, src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def warp(img):\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "    \n",
    "    img = undistort(img)\n",
    "    warped_img = cv2.warpPerspective(img, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "    \n",
    "    return warped_img\n",
    "\n",
    "def unwarp(warped, img_size):\n",
    "    return cv2.warpPerspective(warped, M_inv, img_size, flags=cv2.INTER_LINEAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def line_color_filter(warped_img):\n",
    "    hsv = cv2.cvtColor(warped_img, cv2.COLOR_RGB2HSV).astype(np.float)\n",
    "    \n",
    "    yellow_mask = cv2.inRange(hsv, np.array([20, 50, 50]), np.array([40, 255, 255]))\n",
    "    white_mask = cv2.inRange(hsv, np.array([0, 0, 200]), np.array([255, 70, 255]))\n",
    "    \n",
    "    return cv2.bitwise_and(warped_img, warped_img, mask= white_mask | yellow_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def abs_sobel_thresh(img_channel, orient='x', sobel_kernel=3, thresh=(0, 255)):\n",
    "    sobel = np.zeros(img_channel.shape)\n",
    "    \n",
    "    if orient == 'x':\n",
    "        sobel = cv2.Sobel(img_channel, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    elif orient == 'y':\n",
    "        sobel = cv2.Sobel(img_channel, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    \n",
    "    abs_sobel = np.absolute(sobel)\n",
    "    scaled_sobel = np.uint8(255 * abs_sobel / np.max(abs_sobel))\n",
    "    \n",
    "    binary_output = np.zeros_like(scaled_sobel)\n",
    "    binary_output[(scaled_sobel >= thresh[0]) & (scaled_sobel <= thresh[1])] = 1\n",
    "    \n",
    "    return binary_output\n",
    "\n",
    "def mag_sobel_thresh(img_channel, sobel_kernel=3, thresh=(0, 255)):\n",
    "    sobelx = cv2.Sobel(img_channel, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(img_channel, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    \n",
    "    magn_sobel = np.sqrt(sobelx ** 2 + sobely ** 2)\n",
    "    scaled_sobel = np.uint8(255 * magn_sobel / np.max(magn_sobel))\n",
    "    \n",
    "    binary_output = np.zeros_like(scaled_sobel)\n",
    "    binary_output[(scaled_sobel >= thresh[0]) & (scaled_sobel <= thresh[1])] = 1\n",
    "    \n",
    "    return binary_output\n",
    "\n",
    "def dir_sobel_thresh(img_channel, sobel_kernel=3, thresh=(0, np.pi/2)):\n",
    "    sobelx = cv2.Sobel(img_channel, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(img_channel, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    \n",
    "    abs_sobelx = np.absolute(sobelx)\n",
    "    abs_sobely = np.absolute(sobely)\n",
    "    \n",
    "    gradient_direction = np.uint8(np.arctan2(abs_sobely, abs_sobelx))\n",
    "    \n",
    "    binary_output = np.zeros_like(gradient_direction)\n",
    "    binary_output[(gradient_direction >= thresh[0]) & (gradient_direction <= thresh[1])] = 1\n",
    "\n",
    "    return binary_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Process image to detect the lines by applying a mixture of gradient thresholds.\n",
    "def lines_preprocessing(img, s_thresh=(200, 255), sx_thresh=(50, 100)):\n",
    "    copy = np.copy(img)\n",
    "    \n",
    "    # Convert image to both HSV and HLS\n",
    "    hsv = cv2.cvtColor(copy, cv2.COLOR_RGB2HSV).astype(np.float)\n",
    "    hls = cv2.cvtColor(copy, cv2.COLOR_RGB2HLS).astype(np.float)\n",
    "       \n",
    "    # Grab the HLS Saturation channel\n",
    "    s_channel = hls[:,:,2]\n",
    "    # Grab the HSV Value channel\n",
    "    v_channel = hsv[:,:,2]\n",
    "    \n",
    "    gradx = abs_sobel_thresh(v_channel, orient='x', thresh=sx_thresh)\n",
    "    grady = abs_sobel_thresh(v_channel, orient='y', thresh=sx_thresh)\n",
    "    mag_binary = mag_sobel_thresh(v_channel, sobel_kernel=5, thresh=(200, 255))\n",
    "    dir_binary = dir_sobel_thresh(v_channel, sobel_kernel=5, thresh=(np.pi/4, 3 * np.pi / 4))\n",
    "    \n",
    "    combined_thresh = np.zeros_like(v_channel)\n",
    "    combined_thresh[((gradx == 1) & (grady == 1)) | ((mag_binary == 1) & (dir_binary == 1))] = 1\n",
    "    \n",
    "    # Threshold Saturation channel\n",
    "    s_binary = np.zeros_like(s_channel)\n",
    "    s_binary[(s_channel >= s_thresh[0]) & (s_channel <= s_thresh[1])] = 1\n",
    "    \n",
    "    color_binary = np.dstack((np.zeros_like(combined_thresh), combined_thresh, s_binary))\n",
    "    return color_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_to_binary(channels_binary_img):\n",
    "    binary_img = np.zeros_like(channels_binary_img[:,:,1])\n",
    "    binary_img[(channels_binary_img[:,:,1] == 1) | (channels_binary_img[:,:,2] == 1)] = 1\n",
    "    return binary_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_histogram(binary_img, factor=1.5):\n",
    "    return np.sum(binary_img[int(binary_img.shape[0]//factor):,:], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_line_fits(lines_img, left_line, right_line):\n",
    "    # Convert warped masked image to binary\n",
    "    lines_img = np.uint8(lines_img)\n",
    "    binary_img = convert_to_binary(lines_img)\n",
    "\n",
    "    # Assuming you have created a warped binary image called \"binary_warped\"\n",
    "    # Take a histogram of the bottom half of the image\n",
    "    histogram = get_histogram(binary_img)\n",
    "    # Create an output image to draw on and  visualize the result\n",
    "    out_img = np.dstack((binary_img, binary_img, binary_img)) * 255\n",
    "\n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0]/2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "    # Choose the number of sliding windows\n",
    "    nwindows = 9\n",
    "    # Set height of windows\n",
    "    window_height = np.int(binary_img.shape[0]//nwindows)\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = binary_img.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # Current positions to be updated for each window\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 100\n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 50\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = binary_img.shape[0] - (window+1)*window_height\n",
    "        win_y_high = binary_img.shape[0] - window*window_height\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        # Draw the windows on the visualization image\n",
    "        cv2.rectangle(out_img,(win_xleft_low,win_y_low),(win_xleft_high,win_y_high),(0,255,0), 2) \n",
    "        cv2.rectangle(out_img,(win_xright_low,win_y_low),(win_xright_high,win_y_high),(0,255,0), 2) \n",
    "        # Identify the nonzero pixels in x and y within the window\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xright_low) & (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        # If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "    # Concatenate the arrays of indices\n",
    "    left_lane_inds = np.concatenate(left_lane_inds)\n",
    "    right_lane_inds = np.concatenate(right_lane_inds)\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds] \n",
    "\n",
    "    # If we did not find pixels for one of the lines (left/right), return false, i.e. we couldn't find the line\n",
    "    if lefty.size == 0 or leftx.size == 0 or righty.size == 0 or rightx.size == 0:\n",
    "        return False\n",
    "    \n",
    "    # Fit a second order polynomial to each\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    \n",
    "    left_line.fit = left_fit\n",
    "    right_line.fit = right_fit\n",
    "\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, binary_img.shape[0]-1, binary_img.shape[0] )\n",
    "    left_fitx = left_fit[0] * ploty ** 2 + left_fit[1] * ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0] * ploty ** 2 + right_fit[1] * ploty + right_fit[2]\n",
    "    \n",
    "    left_line.ploty = ploty\n",
    "    right_line.ploty = ploty\n",
    "    \n",
    "    left_line.recent_fitx.append(left_fitx)\n",
    "    right_line.recent_fitx.append(right_fitx)\n",
    "    left_line.average_fits()\n",
    "    right_line.average_fits()\n",
    "    \n",
    "    left_line.fitx = left_fitx\n",
    "    right_line.fitx = right_fitx\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_next_line_fits(lines_img, left_line, right_line):\n",
    "    # Convert warped masked image to binary\n",
    "    lines_img = np.uint8(lines_img)\n",
    "    binary_img = convert_to_binary(lines_img)\n",
    "    \n",
    "    nonzero = binary_img.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    margin = 100\n",
    "    \n",
    "    left_fit = left_line.fit\n",
    "    right_fit = right_line.fit\n",
    "    \n",
    "    left_lane_inds = ((nonzerox > (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2] - margin)) & (nonzerox < (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2] + margin))) \n",
    "    right_lane_inds = ((nonzerox > (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2] - margin)) & (nonzerox < (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2] + margin))) \n",
    "    \n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds]\n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "    \n",
    "    # If we did not find pixels for one of the lines (left/right), return false, i.e. we couldn't find the line\n",
    "    if lefty.size == 0 or leftx.size == 0 or righty.size == 0 or rightx.size == 0:\n",
    "        return False\n",
    "    \n",
    "    # Fit a second order polynomial to each\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    \n",
    "    left_line.fit = left_fit\n",
    "    right_line.fit = right_fit\n",
    "    \n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, binary_img.shape[0] - 1, binary_img.shape[0])\n",
    "    left_fitx = left_fit[0] * ploty ** 2 + left_fit[1] * ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0] * ploty ** 2 + right_fit[1] * ploty + right_fit[2]\n",
    "    \n",
    "    left_line.ploty = ploty\n",
    "    right_line.ploty = ploty\n",
    "    \n",
    "    left_line.recent_fitx.append(left_fitx)\n",
    "    right_line.recent_fitx.append(right_fitx)\n",
    "    left_line.average_fits()\n",
    "    right_line.average_fits()\n",
    "    \n",
    "    left_line.fitx = left_fitx\n",
    "    right_line.fitx = right_fitx\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def draw_lines(img, lines_img, left_line, right_line):\n",
    "    # Create an image to draw the lines on\n",
    "    warp_zero = np.zeros_like(lines_img[:,:,0]).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "    \n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_line.avg_fitx, left_line.ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_line.avg_fitx, right_line.ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0, 255, 0))\n",
    "    \n",
    "    # Warp the blank back to original image space using inverse perspective matrix\n",
    "    newwarp = unwarp(color_warp, img_size=(img.shape[1], img.shape[0]))\n",
    "    \n",
    "    # Combine the result with the original image\n",
    "    result = cv2.addWeighted(img, 1, newwarp, 0.3, 0)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_curvature(left_line, right_line):\n",
    "    # Define conversions in x and y from pixels space to meters\n",
    "    ym_per_pix = 30 / 720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7 / 700 # meters per pixel in x dimension\n",
    "    \n",
    "    ploty = left_line.ploty\n",
    "    y_eval = np.max(ploty)\n",
    "    \n",
    "    # Fit new polynomials to x, y in world space\n",
    "    left_fit_cr = np.polyfit(ploty * ym_per_pix, left_line.avg_fitx * xm_per_pix, 2)\n",
    "    right_fit_cr = np.polyfit(ploty * ym_per_pix, right_line.avg_fitx * xm_per_pix, 2)\n",
    "    \n",
    "    # Calculate the new radii of curvature\n",
    "    left_curverad = ((1 + (2 * left_fit_cr[0] * y_eval * ym_per_pix + left_fit_cr[1]) ** 2) ** 1.5) / np.absolute(2 * left_fit_cr[0])\n",
    "    right_curverad = ((1 + (2 * right_fit_cr[0] * y_eval * ym_per_pix + right_fit_cr[1]) ** 2) ** 1.5) / np.absolute(2 * right_fit_cr[0])\n",
    "    \n",
    "    left_line.curvature = left_curverad\n",
    "    right_line.curvature = right_curverad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_center_offset(img, left_line, right_line):\n",
    "    # Get the center area in between the 2 lines (i.e. the lane area)\n",
    "    lane_center = left_line.fitx[-1] + (right_line.fitx[-1] - left_line.fitx[-1]) / 2 # we look at the last most pixels from each line\n",
    "    xm_per_pix = 3.7 / img.shape[1]\n",
    "    # Car's location is at the center of the image's x axis since the camera is in the center of the front screen\n",
    "    car_center = img.shape[1] / 2\n",
    "    \n",
    "    # Now calculate the offset and scale to meters\n",
    "    offset = (lane_center - car_center) * xm_per_pix\n",
    "    \n",
    "    # Negative offset means the car is to the right of the lane center\n",
    "    # Positive offset means the car is to the left of the lane center\n",
    "    left_line.center_offset = offset\n",
    "    right_line.center_offset = offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "font_face = cv2.FONT_HERSHEY_SIMPLEX\n",
    "font_scale = 1\n",
    "thickness = 3\n",
    "def write_measurements(result_img, left_line, right_line):\n",
    "    avg_curvature = (left_line.curvature + right_line.curvature) / 2\n",
    "    \n",
    "    curvature_text = 'Curvature radius of the lane: ' + str(avg_curvature) + ' m.'\n",
    "    offset_text = 'Vehicle offset from center of lane: ' + str(left_line.center_offset) + ' m.'\n",
    "    \n",
    "    cv2.putText(result_img, curvature_text, (50, 50), font_face, font_scale, (163, 0, 0), thickness)\n",
    "    cv2.putText(result_img, offset_text, (50, 80), font_face, font_scale, (163, 0, 0), thickness)\n",
    "\n",
    "    return result_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now that we have all the individual building blocks, let's start to write the video processing units.\n",
    "\n",
    "First, let's create a helper class that will keep track of all the important params."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "class Line():\n",
    "    MAX_ITERATIONS = 5\n",
    "    MAX_RETRIES = 0\n",
    "    def __init__(self):\n",
    "        # was the line detected in the last iteration?\n",
    "        self.detected = False\n",
    "        # Number of frames after which we restart  the search from scratch\n",
    "        self.retries = self.MAX_RETRIES\n",
    "        # Flag to indicate if this is the first frame\n",
    "        self.is_first_frame = True\n",
    "        \n",
    "        # x values of the last n fits of the line\n",
    "        self.recent_fitx = deque(maxlen=self.MAX_ITERATIONS)\n",
    "        # average x values of the fitted line over the last n iterations\n",
    "        self.avg_fitx = None     \n",
    "\n",
    "        # current y values\n",
    "        self.ploty = None\n",
    "        # current x values\n",
    "        self.fitx = None\n",
    "        # current fit\n",
    "        self.fit = None\n",
    "\n",
    "        # radius of curvature of the line in some units\n",
    "        self.curvature = None \n",
    "        # distance in meters of vehicle center from the line\n",
    "        self.center_offset = None\n",
    "    \n",
    "    def average_fits(self):\n",
    "        self.avg_fitx = np.mean(self.recent_fitx, axis=0)\n",
    "    \n",
    "    def reset_retries(self):\n",
    "        self.retries = self.MAX_RETRIES\n",
    "    \n",
    "    def has_previous_fit(self):\n",
    "        return self.avg_fitx is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "global left_line\n",
    "global right_line\n",
    "left_line = None\n",
    "right_line = None\n",
    "def process_image(image):\n",
    "    global left_line\n",
    "    global right_line\n",
    "    # Initialize the line objects in case this is the first frame\n",
    "    if left_line is None:\n",
    "        left_line = Line()\n",
    "    if right_line is None:\n",
    "        right_line = Line()\n",
    "    \n",
    "    # Process the image: warping, color extraction, and gradient thresholding\n",
    "    warped_img = warp(image)\n",
    "    masked_img = line_color_filter(warped_img)\n",
    "    lines_img = lines_preprocessing(masked_img)\n",
    "    \n",
    "    # If this is the first frame, start searching for the lines\n",
    "    if left_line.is_first_frame is True and right_line.is_first_frame is True:\n",
    "        # Get the initial line fits from scratch\n",
    "        success = get_line_fits(lines_img, left_line, right_line)\n",
    "        left_line.detected = success\n",
    "        right_line.detected = success\n",
    "\n",
    "        left_line.is_first_frame = False\n",
    "        right_line.is_first_frame = False\n",
    "    # If we are not first frame\n",
    "    else:\n",
    "        # If we do not even have a previous fit or we are out of retries, start from scratch\n",
    "        if (left_line.has_previous_fit() is False and right_line.has_previous_fit() is False) \\\n",
    "            or (left_line.retries == 0 and right_line.retries == 0):\n",
    "            success = get_line_fits(lines_img, left_line, right_line)\n",
    "            left_line.detected = success\n",
    "            right_line.detected = success\n",
    "            \n",
    "            if success is True:\n",
    "                left_line.reset_retries()\n",
    "                right_line.reset_retries()\n",
    "        # If we still have retries, continue from a previous fit\n",
    "        elif left_line.retries > 0 and right_line.retries > 0:\n",
    "            # If we do not have a previous successful fit, this is a retry\n",
    "            if left_line.detected is False and right_line.detected is False:\n",
    "                left_line.retries -= 1\n",
    "                right_line.retries -= 1\n",
    "            \n",
    "            success = get_next_line_fits(lines_img, left_line, right_line)\n",
    "            left_line.detected = success\n",
    "            right_line.detected = success\n",
    "            \n",
    "            # If we were successful in this attempt to find a fit, reset the number of retries\n",
    "            if success is True:\n",
    "                left_line.reset_retries()\n",
    "                right_line.reset_retries()\n",
    "            \n",
    "        # If we went over the retry limit and still didn't detect lines, start searching for lines from scratch again\n",
    "        if left_line.retries == 0 and right_line.retries == 0 \\\n",
    "            and left_line.detected is False and right_line.detected is False:\n",
    "            left_line.reset_retries()\n",
    "            right_line.reset_retries()\n",
    "            # Search for lines from scratch\n",
    "            success = get_line_fits(lines_img, left_line, right_line)\n",
    "            left_line.detected = success\n",
    "            right_line.detected = success\n",
    "    \n",
    "    # Only draw lines if we have a fit (current or previous) to draw\n",
    "    if left_line.has_previous_fit() is True and right_line.has_previous_fit() is True:\n",
    "        result = draw_lines(image, lines_img, left_line, right_line)\n",
    "    else:\n",
    "        # We are not able to draw any lines because we do not have any fits\n",
    "        result = image\n",
    "\n",
    "    get_curvature(left_line, right_line)\n",
    "    get_center_offset(image, left_line, right_line)\n",
    "    \n",
    "    result = write_measurements(result, left_line, right_line)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "left_line = None\n",
    "right_line = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video result.mp4\n",
      "[MoviePy] Writing video result.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████▉| 1260/1261 [06:10<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: result.mp4 \n",
      "\n",
      "Wall time: 6min 11s\n"
     ]
    }
   ],
   "source": [
    "output = 'result.mp4'\n",
    "clip1 = VideoFileClip(\"project_video.mp4\")\n",
    "result_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time result_clip.write_videofile(output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"result.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "left_line = None\n",
    "right_line = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video result_challenge.mp4\n",
      "[MoviePy] Writing video result_challenge.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████| 485/485 [02:24<00:00,  3.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: result_challenge.mp4 \n",
      "\n",
      "Wall time: 2min 25s\n"
     ]
    }
   ],
   "source": [
    "output = 'result_challenge.mp4'\n",
    "clip1 = VideoFileClip(\"challenge_video.mp4\")\n",
    "result_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time result_clip.write_videofile(output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"result_challenge.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Harder Challenge Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "left_line = None\n",
    "right_line = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video result_harder_challenge.mp4\n",
      "[MoviePy] Writing video result_harder_challenge.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████▉| 1199/1200 [06:12<00:00,  3.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: result_harder_challenge.mp4 \n",
      "\n",
      "Wall time: 6min 13s\n"
     ]
    }
   ],
   "source": [
    "output = 'result_harder_challenge.mp4'\n",
    "clip1 = VideoFileClip(\"harder_challenge_video.mp4\")\n",
    "result_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time result_clip.write_videofile(output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"result_harder_challenge.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
