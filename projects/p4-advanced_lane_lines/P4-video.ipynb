{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 4: Advanced Lane Finding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "In this project we would improve our technique for finding road lanes and curvature of the lanes. In order to do this, we would use a series of steps, outlined below:\n",
    "\n",
    "1. Camera Calibration\n",
    "2. Distortion Correction\n",
    "3. Color and Gradient Thresholds\n",
    "4. Perspective Transform\n",
    "5. Detect Lane Lines\n",
    "6. Determine Lane Curvature\n",
    "7. Apply these techniques to the frames of the video\n",
    "\n",
    "In this particular notebook, we would approach number 7., applying all the building blocks to the video frames!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Apply these techniques to the frames of the video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by moving over all the methods defined in the development notebook, getting them ready to use in the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "calibration_params_file = 'dist_pickle.p'\n",
    "\n",
    "with open(calibration_params_file, 'rb') as f:\n",
    "    calibration_params = pickle.load(f)\n",
    "\n",
    "mtx = calibration_params[\"mtx\"]\n",
    "dist = calibration_params[\"dist\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def undistort(img):\n",
    "    return cv2.undistort(img, mtx, dist, None, mtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_img = mpimg.imread('test_images/straight_lines1.jpg')\n",
    "test_img_size = (test_img.shape[1], test_img.shape[0])\n",
    "\n",
    "x1, y1 = (500, 480)\n",
    "x2, y2 = (780, 480)\n",
    "x3, y3 = (1200, 670)\n",
    "x4, y4 = (80, 670)\n",
    "\n",
    "src = np.float32(\n",
    "    [[x1, y1],\n",
    "     [x2, y2],\n",
    "     [x3, y3],\n",
    "     [x4, y4]])\n",
    "\n",
    "offset = 10\n",
    "dst = np.float32(\n",
    "    [[offset, offset],\n",
    "     [test_img_size[0] - offset, offset],\n",
    "     [test_img_size[0] - offset, test_img_size[1] - offset],\n",
    "     [offset, test_img_size[1] - offset]])\n",
    "\n",
    "M = cv2.getPerspectiveTransform(src, dst)\n",
    "M_inv = cv2.getPerspectiveTransform(dst, src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def warp(img):\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "    \n",
    "    img = undistort(img)\n",
    "    warped_img = cv2.warpPerspective(img, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "    \n",
    "    return warped_img\n",
    "\n",
    "def unwarp(warped, img_size):\n",
    "    return cv2.warpPerspective(warped, M_inv, img_size, flags=cv2.INTER_LINEAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def line_color_filter(warped_img):\n",
    "    hsv = cv2.cvtColor(warped_img, cv2.COLOR_RGB2HSV).astype(np.float)\n",
    "    \n",
    "    yellow_mask = cv2.inRange(hsv, np.array([20, 50, 50]), np.array([40, 255, 255]))\n",
    "    white_mask = cv2.inRange(hsv, np.array([0, 0, 200]), np.array([255, 70, 255]))\n",
    "    \n",
    "    return cv2.bitwise_and(warped_img, warped_img, mask= white_mask | yellow_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def abs_sobel_thresh(img_channel, orient='x', sobel_kernel=3, thresh=(0, 255)):\n",
    "    sobel = np.zeros(img_channel.shape)\n",
    "    \n",
    "    if orient == 'x':\n",
    "        sobel = cv2.Sobel(img_channel, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    elif orient == 'y':\n",
    "        sobel = cv2.Sobel(img_channel, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    \n",
    "    abs_sobel = np.absolute(sobel)\n",
    "    scaled_sobel = np.uint8(255 * abs_sobel / np.max(abs_sobel))\n",
    "    \n",
    "    binary_output = np.zeros_like(scaled_sobel)\n",
    "    binary_output[(scaled_sobel >= thresh[0]) & (scaled_sobel <= thresh[1])] = 1\n",
    "    \n",
    "    return binary_output\n",
    "\n",
    "def mag_sobel_thresh(img_channel, sobel_kernel=3, thresh=(0, 255)):\n",
    "    sobelx = cv2.Sobel(img_channel, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(img_channel, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    \n",
    "    magn_sobel = np.sqrt(sobelx ** 2 + sobely ** 2)\n",
    "    scaled_sobel = np.uint8(255 * magn_sobel / np.max(magn_sobel))\n",
    "    \n",
    "    binary_output = np.zeros_like(scaled_sobel)\n",
    "    binary_output[(scaled_sobel >= thresh[0]) & (scaled_sobel <= thresh[1])] = 1\n",
    "    \n",
    "    return binary_output\n",
    "\n",
    "def dir_sobel_thresh(img_channel, sobel_kernel=3, thresh=(0, np.pi/2)):\n",
    "    sobelx = cv2.Sobel(img_channel, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(img_channel, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    \n",
    "    abs_sobelx = np.absolute(sobelx)\n",
    "    abs_sobely = np.absolute(sobely)\n",
    "    \n",
    "    gradient_direction = np.uint8(np.arctan2(abs_sobely, abs_sobelx))\n",
    "    \n",
    "    binary_output = np.zeros_like(gradient_direction)\n",
    "    binary_output[(gradient_direction >= thresh[0]) & (gradient_direction <= thresh[1])] = 1\n",
    "\n",
    "    return binary_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lines_preprocessing(img, s_thresh=(200, 255), sx_thresh=(50, 100)):\n",
    "    copy = np.copy(img)\n",
    "    \n",
    "    # Convert image to both HSV and HLS as described above\n",
    "    hsv = cv2.cvtColor(copy, cv2.COLOR_RGB2HSV).astype(np.float)\n",
    "    hls = cv2.cvtColor(copy, cv2.COLOR_RGB2HLS).astype(np.float)\n",
    "       \n",
    "    # Grab the HLS Saturation channel\n",
    "    s_channel = hls[:,:,2]\n",
    "    # Grab the HSV Value channel\n",
    "    v_channel = hsv[:,:,2]\n",
    "    \n",
    "    gradx = abs_sobel_thresh(v_channel, orient='x', thresh=sx_thresh)\n",
    "    grady = abs_sobel_thresh(v_channel, orient='y', thresh=sx_thresh)\n",
    "    mag_binary = mag_sobel_thresh(v_channel, sobel_kernel=5, thresh=(200, 255))\n",
    "    dir_binary = dir_sobel_thresh(v_channel, sobel_kernel=5, thresh=(np.pi/4, 3 * np.pi / 4))\n",
    "    \n",
    "    combined_thresh = np.zeros_like(v_channel)\n",
    "    combined_thresh[((gradx == 1) & (grady == 1)) | ((mag_binary == 1) & (dir_binary == 1))] = 1\n",
    "    \n",
    "    # Threshold Saturation channel\n",
    "    s_binary = np.zeros_like(s_channel)\n",
    "    s_binary[(s_channel >= s_thresh[0]) & (s_channel <= s_thresh[1])] = 1\n",
    "    \n",
    "    color_binary = np.dstack((np.zeros_like(combined_thresh), combined_thresh, s_binary))\n",
    "    return color_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_to_binary(channels_binary_img):\n",
    "    binary_img = np.zeros_like(channels_binary_img[:,:,1])\n",
    "    binary_img[(channels_binary_img[:,:,1] == 1) | (channels_binary_img[:,:,2] == 1)] = 1\n",
    "    return binary_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_histogram(binary_img, factor=1.5):\n",
    "    return np.sum(binary_img[int(binary_img.shape[0]//factor):,:], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_line_fits(lines_img, plot=False):\n",
    "    # Convert warped masked image to binary\n",
    "    lines_img = np.uint8(lines_img)\n",
    "    binary_img = convert_to_binary(lines_img)\n",
    "\n",
    "    # Assuming you have created a warped binary image called \"binary_warped\"\n",
    "    # Take a histogram of the bottom half of the image\n",
    "    histogram = get_histogram(binary_img)\n",
    "    # Create an output image to draw on and  visualize the result\n",
    "    out_img = np.dstack((binary_img, binary_img, binary_img)) * 255\n",
    "\n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0]/2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "    # Choose the number of sliding windows\n",
    "    nwindows = 9\n",
    "    # Set height of windows\n",
    "    window_height = np.int(binary_img.shape[0]//nwindows)\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = binary_img.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # Current positions to be updated for each window\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 100\n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 50\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = binary_img.shape[0] - (window+1)*window_height\n",
    "        win_y_high = binary_img.shape[0] - window*window_height\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        # Draw the windows on the visualization image\n",
    "        cv2.rectangle(out_img,(win_xleft_low,win_y_low),(win_xleft_high,win_y_high),(0,255,0), 2) \n",
    "        cv2.rectangle(out_img,(win_xright_low,win_y_low),(win_xright_high,win_y_high),(0,255,0), 2) \n",
    "        # Identify the nonzero pixels in x and y within the window\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xright_low) & (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        # If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "    # Concatenate the arrays of indices\n",
    "    left_lane_inds = np.concatenate(left_lane_inds)\n",
    "    right_lane_inds = np.concatenate(right_lane_inds)\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds] \n",
    "\n",
    "    # Fit a second order polynomial to each\n",
    "    if lefty.size == 0 or leftx.size == 0 or righty.size == 0 or rightx.size == 0:\n",
    "        return None\n",
    "    \n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "\n",
    "    if plot == True:\n",
    "        # Generate x and y values for plotting\n",
    "        ploty = np.linspace(0, binary_img.shape[0]-1, binary_img.shape[0] )\n",
    "        left_fitx = left_fit[0] * ploty ** 2 + left_fit[1] * ploty + left_fit[2]\n",
    "        right_fitx = right_fit[0] * ploty ** 2 + right_fit[1] * ploty + right_fit[2]\n",
    "\n",
    "        out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "        out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "        plt.imshow(out_img)\n",
    "        plt.plot(left_fitx, ploty, color='yellow')\n",
    "        plt.plot(right_fitx, ploty, color='yellow')\n",
    "        plt.xlim(0, 1280)\n",
    "        plt.ylim(720, 0)\n",
    "        plt.show()\n",
    "    \n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, binary_img.shape[0]-1, binary_img.shape[0] )\n",
    "    left_fitx = left_fit[0] * ploty ** 2 + left_fit[1] * ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0] * ploty ** 2 + right_fit[1] * ploty + right_fit[2]\n",
    "    \n",
    "    return (left_fit, right_fit), (left_fitx, right_fitx, ploty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_next_line_fits(lines_img, left_fit, right_fit):\n",
    "    # Convert warped masked image to binary\n",
    "    lines_img = np.uint8(lines_img)\n",
    "    binary_img = convert_to_binary(lines_img)\n",
    "    \n",
    "    nonzero = binary_img.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    margin = 100\n",
    "    left_lane_inds = ((nonzerox > (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2] - margin)) & (nonzerox < (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2] + margin))) \n",
    "    right_lane_inds = ((nonzerox > (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2] - margin)) & (nonzerox < (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2] + margin))) \n",
    "    \n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds]\n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "    \n",
    "    # Fit a second order polynomial to each\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    \n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, binary_img.shape[0] - 1, binary_img.shape[0])\n",
    "    left_fitx = left_fit[0] * ploty ** 2 + left_fit[1] * ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0] * ploty ** 2 + right_fit[1] * ploty + right_fit[2]\n",
    "    \n",
    "    return (left_fit, right_fit), (left_fitx, right_fitx, ploty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def draw_lines(img, lines_img, left_fitx, right_fitx, ploty):\n",
    "    # Create an image to draw the lines on\n",
    "    warp_zero = np.zeros_like(lines_img[:,:,0]).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "    \n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0, 255, 0))\n",
    "    \n",
    "    # Warp the blank back to original image space using inverse perspective matrix\n",
    "    newwarp = unwarp(color_warp, img_size=(img.shape[1], img.shape[0]))\n",
    "    \n",
    "    # Combine the result with the original image\n",
    "    result = cv2.addWeighted(img, 1, newwarp, 0.3, 0)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_curvature(leftx, rightx, ploty):\n",
    "    # Define conversions in x and y from pixels space to meters\n",
    "    ym_per_pix = 30 / 720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7 / 700 # meters per pixel in x dimension\n",
    "    \n",
    "    y_eval = np.max(ploty)\n",
    "    \n",
    "    # Fit new polynomials to x, y in world space\n",
    "    left_fit_cr = np.polyfit(ploty * ym_per_pix, leftx * xm_per_pix, 2)\n",
    "    right_fit_cr = np.polyfit(ploty * ym_per_pix, rightx * xm_per_pix, 2)\n",
    "    \n",
    "    # Calculate the new radii of curvature\n",
    "    left_curverad = ((1 + (2 * left_fit_cr[0] * y_eval * ym_per_pix + left_fit_cr[1]) ** 2) ** 1.5) / np.absolute(2 * left_fit_cr[0])\n",
    "    right_curverad = ((1 + (2 * right_fit_cr[0] * y_eval * ym_per_pix + right_fit_cr[1]) ** 2) ** 1.5) / np.absolute(2 * right_fit_cr[0])\n",
    "    \n",
    "    # Now our radius of curvature is in meters\n",
    "    # print (left_curverad, 'm', right_curverad, 'm')\n",
    "    \n",
    "    return left_curverad, right_curverad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_center_offset(img, left_fitx, right_fitx):\n",
    "    # Get the center area in between the 2 lines (i.e. the lane area)\n",
    "    lane_center = left_fitx[-1] + (right_fitx[-1] - left_fitx[-1]) / 2 # we look at the last most pixels from each line\n",
    "    xm_per_pix = 3.7 / img.shape[1]\n",
    "    # Car's location is at the center of the image's x axis since the camera is in the center of the front screen\n",
    "    car_center = img.shape[1] / 2\n",
    "    \n",
    "    # Now calculate the offset and scale to meters\n",
    "    offset = (lane_center - car_center) * xm_per_pix\n",
    "    \n",
    "    # Negative offset means the car is to the right of the lane center\n",
    "    # Positive offset means the car is to the left of the lane center\n",
    "    return offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "font_face = cv2.FONT_HERSHEY_SIMPLEX\n",
    "font_scale = 1\n",
    "thickness = 3\n",
    "def write_measurements(result_img, left_cur, right_cur, center_offset):\n",
    "    avg_curvature = (left_cur + right_cur) / 2\n",
    "    \n",
    "    curvature_text = 'Curvature radius of the lane: ' + str(avg_curvature) + ' m.'\n",
    "    offset_text = 'Vehicle offset from center of lane: ' + str(center_offset) + ' m.'\n",
    "    \n",
    "    cv2.putText(result_img, curvature_text, (50, 50), font_face, font_scale, (163, 0, 0), thickness)\n",
    "    cv2.putText(result_img, offset_text, (50, 80), font_face, font_scale, (163, 0, 0), thickness)\n",
    "\n",
    "    return result_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now that we have all the individual building blocks, let's start to write the video processing units.\n",
    "\n",
    "First, let's create a helper class that will keep track of all the important params."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "class Line():\n",
    "    MAX_ITERATIONS = 5\n",
    "    def __init__(self):\n",
    "        # was the line detected in the last iteration?\n",
    "        self.detected = False\n",
    "        \n",
    "        # x values of the last n fits of the line\n",
    "        self.recent_xfitted = deque(maxlen=MAX_ITERATIONS)\n",
    "        #average x values of the fitted line over the last n iterations\n",
    "        self.bestx = None     \n",
    "        #polynomial coefficients averaged over the last n iterations\n",
    "        self.best_fit = None  \n",
    "        \n",
    "        #polynomial coefficients for the most recent fit\n",
    "        self.current_fit = [np.array([False])] \n",
    "        \n",
    "        #radius of curvature of the line in some units\n",
    "        self.radius_of_curvature = None \n",
    "        #distance in meters of vehicle center from the line\n",
    "        self.center_offset = None \n",
    "        \n",
    "        #x values for detected line pixels\n",
    "        self.allx = None  \n",
    "        #y values for detected line pixels\n",
    "        self.ally = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "    warped_img = warp(image)\n",
    "    masked_img = line_color_filter(warped_img)\n",
    "    lines_img = lines_preprocessing(masked_img)\n",
    "\n",
    "    # Getting the initial fits\n",
    "    fits = get_line_fits(lines_img)\n",
    "    \n",
    "    if fits is None:\n",
    "        return image\n",
    "    \n",
    "    (_, _), (left_fitx, right_fitx, ploty) = fits\n",
    "    result = draw_lines(image, lines_img, left_fitx, right_fitx, ploty)\n",
    "\n",
    "    left_cur, right_cur = get_curvature(left_fitx, right_fitx, ploty)\n",
    "    center_offset = get_center_offset(image, left_fitx, right_fitx)\n",
    "    \n",
    "    result = write_measurements(result, left_cur, right_cur, center_offset)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video result.mp4\n",
      "[MoviePy] Writing video result.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████▉| 1260/1261 [06:03<00:00,  3.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: result.mp4 \n",
      "\n",
      "Wall time: 6min 4s\n"
     ]
    }
   ],
   "source": [
    "output = 'result.mp4'\n",
    "clip1 = VideoFileClip(\"project_video.mp4\")\n",
    "result_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time result_clip.write_videofile(output, audio=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play the video inline, or if you prefer find the video in your filesystem (should be in the same directory) and play it in your video player of choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"result.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video result_challenge.mp4\n",
      "[MoviePy] Writing video result_challenge.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████| 485/485 [02:21<00:00,  3.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: result_challenge.mp4 \n",
      "\n",
      "Wall time: 2min 22s\n"
     ]
    }
   ],
   "source": [
    "output = 'result_challenge.mp4'\n",
    "clip1 = VideoFileClip(\"challenge_video.mp4\")\n",
    "result_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time result_clip.write_videofile(output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"result_challenge.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video result_harder_challenge.mp4\n",
      "[MoviePy] Writing video result_harder_challenge.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████▉| 1199/1200 [06:14<00:00,  3.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: result_harder_challenge.mp4 \n",
      "\n",
      "Wall time: 6min 16s\n"
     ]
    }
   ],
   "source": [
    "output = 'result_harder_challenge.mp4'\n",
    "clip1 = VideoFileClip(\"harder_challenge_video.mp4\")\n",
    "result_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time result_clip.write_videofile(output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"result_harder_challenge.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
